{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 22500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 59.82179641723633,
      "learning_rate": 4.888888888888889e-05,
      "loss": 1.4079,
      "step": 500
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 38.13126754760742,
      "learning_rate": 4.7777777777777784e-05,
      "loss": 1.2461,
      "step": 1000
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 37.83147430419922,
      "learning_rate": 4.666666666666667e-05,
      "loss": 1.2243,
      "step": 1500
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 12.96651840209961,
      "learning_rate": 4.555555555555556e-05,
      "loss": 1.2327,
      "step": 2000
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 61.97023010253906,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 1.1599,
      "step": 2500
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 47.99311828613281,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 1.1924,
      "step": 3000
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 54.41716384887695,
      "learning_rate": 4.222222222222222e-05,
      "loss": 1.1615,
      "step": 3500
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 16.89512062072754,
      "learning_rate": 4.111111111111111e-05,
      "loss": 1.1659,
      "step": 4000
    },
    {
      "epoch": 0.2,
      "grad_norm": 13.136641502380371,
      "learning_rate": 4e-05,
      "loss": 1.1747,
      "step": 4500
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 55.6456413269043,
      "learning_rate": 3.888888888888889e-05,
      "loss": 1.1817,
      "step": 5000
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 81.09925079345703,
      "learning_rate": 3.777777777777778e-05,
      "loss": 1.1691,
      "step": 5500
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 45.766082763671875,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 1.2129,
      "step": 6000
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 25.949243545532227,
      "learning_rate": 3.555555555555556e-05,
      "loss": 1.1534,
      "step": 6500
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 119.32589721679688,
      "learning_rate": 3.444444444444445e-05,
      "loss": 1.1081,
      "step": 7000
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 21.364620208740234,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.099,
      "step": 7500
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 61.96540832519531,
      "learning_rate": 3.222222222222223e-05,
      "loss": 1.0794,
      "step": 8000
    },
    {
      "epoch": 0.37777777777777777,
      "grad_norm": 9.595385551452637,
      "learning_rate": 3.111111111111111e-05,
      "loss": 1.0956,
      "step": 8500
    },
    {
      "epoch": 0.4,
      "grad_norm": 28.390655517578125,
      "learning_rate": 3e-05,
      "loss": 1.0599,
      "step": 9000
    },
    {
      "epoch": 0.4222222222222222,
      "grad_norm": 35.04601287841797,
      "learning_rate": 2.8888888888888888e-05,
      "loss": 1.0654,
      "step": 9500
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 54.306373596191406,
      "learning_rate": 2.777777777777778e-05,
      "loss": 1.0933,
      "step": 10000
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 22.744787216186523,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 1.0826,
      "step": 10500
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 25.739883422851562,
      "learning_rate": 2.5555555555555554e-05,
      "loss": 0.9308,
      "step": 11000
    },
    {
      "epoch": 0.5111111111111111,
      "grad_norm": 38.21860885620117,
      "learning_rate": 2.4444444444444445e-05,
      "loss": 1.1107,
      "step": 11500
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 16.762527465820312,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 1.0622,
      "step": 12000
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 17.13071632385254,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 1.0479,
      "step": 12500
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 47.45425033569336,
      "learning_rate": 2.111111111111111e-05,
      "loss": 1.0426,
      "step": 13000
    },
    {
      "epoch": 0.6,
      "grad_norm": 36.515464782714844,
      "learning_rate": 2e-05,
      "loss": 1.0847,
      "step": 13500
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 0.18625128269195557,
      "learning_rate": 1.888888888888889e-05,
      "loss": 0.9883,
      "step": 14000
    },
    {
      "epoch": 0.6444444444444445,
      "grad_norm": 73.42945861816406,
      "learning_rate": 1.777777777777778e-05,
      "loss": 1.0736,
      "step": 14500
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 50.54946517944336,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 1.0914,
      "step": 15000
    },
    {
      "epoch": 0.6888888888888889,
      "grad_norm": 24.290082931518555,
      "learning_rate": 1.5555555555555555e-05,
      "loss": 0.9872,
      "step": 15500
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 58.650997161865234,
      "learning_rate": 1.4444444444444444e-05,
      "loss": 1.029,
      "step": 16000
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 5.783419132232666,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 1.0136,
      "step": 16500
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 1.105972170829773,
      "learning_rate": 1.2222222222222222e-05,
      "loss": 1.0073,
      "step": 17000
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 34.16461181640625,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 1.0022,
      "step": 17500
    },
    {
      "epoch": 0.8,
      "grad_norm": 11.873117446899414,
      "learning_rate": 1e-05,
      "loss": 1.0416,
      "step": 18000
    },
    {
      "epoch": 0.8222222222222222,
      "grad_norm": 12.60718059539795,
      "learning_rate": 8.88888888888889e-06,
      "loss": 1.0178,
      "step": 18500
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 13.430499076843262,
      "learning_rate": 7.777777777777777e-06,
      "loss": 1.0405,
      "step": 19000
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 67.31404113769531,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.9985,
      "step": 19500
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 54.287471771240234,
      "learning_rate": 5.555555555555556e-06,
      "loss": 0.9947,
      "step": 20000
    },
    {
      "epoch": 0.9111111111111111,
      "grad_norm": 50.131710052490234,
      "learning_rate": 4.444444444444445e-06,
      "loss": 1.0352,
      "step": 20500
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 12.121769905090332,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.9699,
      "step": 21000
    },
    {
      "epoch": 0.9555555555555556,
      "grad_norm": 1.0554029941558838,
      "learning_rate": 2.2222222222222225e-06,
      "loss": 0.8948,
      "step": 21500
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 9.396125793457031,
      "learning_rate": 1.1111111111111112e-06,
      "loss": 1.011,
      "step": 22000
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.531905174255371,
      "learning_rate": 0.0,
      "loss": 0.9602,
      "step": 22500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6664369106292725,
      "eval_runtime": 10659.5655,
      "eval_samples_per_second": 4.222,
      "eval_steps_per_second": 0.528,
      "step": 22500
    }
  ],
  "logging_steps": 500,
  "max_steps": 22500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 2.98046331648e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
